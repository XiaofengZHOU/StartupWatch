{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import time\n",
    "\n",
    "import sys\n",
    "\n",
    "firefox_capabilities = DesiredCapabilities.FIREFOX\n",
    "firefox_capabilities['marionette'] = True\n",
    "firefox_capabilities['handleAlerts'] = True\n",
    "firefox_capabilities['acceptSslCerts'] = True\n",
    "firefox_capabilities['acceptInsecureCerts'] = True\n",
    "geckoPath = 'driver/geckodriver.exe'\n",
    "\n",
    "firefox = webdriver.Firefox(capabilities=firefox_capabilities, executable_path=geckoPath)\n",
    "driver = webdriver.PhantomJS(executable_path='driver/phantomjs.exe')\n",
    "\n",
    "try:\n",
    "    firefox.get('https://www.crunchbase.com/organization/apple')\n",
    "except:\n",
    "    pass\n",
    "driver.get('https://techcrunch.com/')\n",
    "firefox.set_page_load_timeout(2)\n",
    "driver.set_page_load_timeout(30)\n",
    "\n",
    "def existence_in_crunchbase(name):\n",
    "    base_url = 'www.crunchbase.com'\n",
    "    url = 'https://techcrunch.com/search/'+name\n",
    "    url_crunchbase = None\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except:\n",
    "        print('timeout of phantomjs')\n",
    "        pass\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    blocks = soup.select(\"h2.post-title a\")\n",
    "    if len(blocks)>0:\n",
    "        url_crunchbase = blocks[0][\"href\"]  \n",
    "        name  = blocks[0].getText()\n",
    " \n",
    "        if base_url not in url_crunchbase:\n",
    "            url_crunchbase = None\n",
    "    \n",
    "    return url_crunchbase\n",
    "            \n",
    "\n",
    "def extract_company_techcrunch(name,url):\n",
    "    try:\n",
    "        firefox.get(url)\n",
    "    except:\n",
    "        pass\n",
    "    founded = None\n",
    "    employees = None\n",
    "    company_name = ''\n",
    "    blocks_dt = []\n",
    "    blocks_dd = []\n",
    "    try:\n",
    "        soup = BeautifulSoup(firefox.page_source, \"html.parser\")\n",
    "        blocks_dt = soup.select(\"div.details dt\")\n",
    "        blocks_dd = soup.select(\"div.details dd\")\n",
    "        company_name_tag = soup.select_one(\"#profile_header_heading\")\n",
    "        if company_name_tag == None:\n",
    "            company_name = ''\n",
    "        else:\n",
    "            company_name = company_name_tag.getText()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    i = 0\n",
    "    while company_name.lower() != name.lower() and len(blocks_dt)!=0 :\n",
    "        time.sleep(0.3)\n",
    "        try:\n",
    "            soup = BeautifulSoup(firefox.page_source, \"html.parser\")\n",
    "            company_name_tag = soup.select_one(\"#profile_header_heading\")\n",
    "            if company_name_tag:\n",
    "                company_name = company_name_tag.getText()\n",
    "            else:\n",
    "                company_name = ''\n",
    "            blocks_dt = soup.select(\"div.details dt\")\n",
    "            blocks_dd = soup.select(\"div.details dd\")\n",
    "        except KeyboardInterrupt:\n",
    "            sys.exit()\n",
    "        except:\n",
    "            pass\n",
    "        i=i+1\n",
    "        if i >= 100:\n",
    "            print('fail to crawl ', name , ' in crunchbase')\n",
    "            break\n",
    "\n",
    "    \n",
    "    if company_name.lower() == name.lower():\n",
    "        for index,block in enumerate(blocks_dt):\n",
    "            if 'Founded' in  block.getText() : \n",
    "                founded = blocks_dd[index].getText()\n",
    "            if 'Employees' in block.getText():\n",
    "                employees = blocks_dd[index].getText().split('|')[0]\n",
    "    print( name , founded , employees)\n",
    "    return founded,employees\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "class CompaniesManager:\n",
    "    def __init__(self):\n",
    "        self.companies = []\n",
    "        self.articles = []\n",
    "        self.companies_name = []\n",
    "        self.load_articles()\n",
    "        self.load_companies()\n",
    "        \n",
    "    def load_articles(self):\n",
    "        if os.path.isfile('data/raw_articles.json'):\n",
    "            f = open('data/raw_articles.json')\n",
    "            self.articles = json.load(f)\n",
    "            f.close()\n",
    "            \n",
    "    def load_companies(self):\n",
    "        if os.path.isfile('data/raw_companies.json'):\n",
    "            f = open('data/raw_companies.json')\n",
    "            self.companies = json.load(f)\n",
    "            f.close()      \n",
    "            for company in self.companies:\n",
    "                name = company[\"name\"]\n",
    "                self.companies_name.append(name)\n",
    "        \n",
    "            \n",
    "    def extract_companies(self):\n",
    "        \n",
    "        for index,article in enumerate(self.articles):\n",
    "            for company_name in article[\"companies\"]: \n",
    "                article_extraInfos = article[\"extra_infos\"]\n",
    "                for info in article_extraInfos:\n",
    "                    if info[\"text\"]== company_name:\n",
    "                        relevance = info[\"relevance\"]\n",
    "                        count_in_article = info[\"count\"]\n",
    "                            \n",
    "                if company_name in self.companies_name :\n",
    "                    for company in self.companies:\n",
    "                        if company_name == company[\"name\"] and article[\"id\"] not in company[\"articles\"]: \n",
    "                            company[\"count\"] = company[\"count\"]+1\n",
    "                            company[\"sentiment\"]= company[\"sentiment\"]+article[\"sentiment\"]\n",
    "                            company[\"articles\"].append(article[\"id\"])\n",
    "                            extra_infos = {\n",
    "                                 \"id\":article[\"id\"] ,\n",
    "                                 \"count_in_article\":count_in_article,\n",
    "                                 \"revelance\": relevance       \n",
    "                            }\n",
    "                            company[\"extra_infos\"].append(extra_infos)\n",
    "                            \n",
    "                else:\n",
    "                    company = {\n",
    "                        \"name\": company_name,\n",
    "                        \"dateFound\": int(str(time.time()).split('.')[0]),\n",
    "                        \"count\":1,\n",
    "                        \"sentiment\": article[\"sentiment\"],\n",
    "                        \"articles\": [article[\"id\"]],\n",
    "                        \"extra_infos\":\n",
    "                        [\n",
    "                            {\n",
    "                             \"id\": article[\"id\"],\n",
    "                             \"count_in_article\":count_in_article,\n",
    "                             \"revelance\": relevance\n",
    "                            }  \n",
    "                        ]    \n",
    "                    }\n",
    "                    self.companies.append(company)\n",
    "                    self.companies_name.append(company_name)\n",
    "            \n",
    "        self.save_to_disk()\n",
    "        \n",
    "    def extend_crunch(self):\n",
    "        \n",
    "        i = 0\n",
    "        for index,company in enumerate(self.companies):\n",
    "            name = company[\"name\"]\n",
    "            if \"search_label\" not in company:\n",
    "                url_crunchbase = existence_in_crunchbase(name)\n",
    "                \n",
    "                if url_crunchbase != None:\n",
    "                    print(name, ' in crunchbase')\n",
    "                    i=i+1\n",
    "                    founded,employees = extract_company_techcrunch(name,url_crunchbase)\n",
    "                    company[\"search_label\"] = url_crunchbase\n",
    "                    if founded is not None:\n",
    "                        company[\"foundationDate\"] = founded\n",
    "                    if employees is not None:\n",
    "                        company[\"number_of_employees\"] = employees\n",
    "                    \n",
    "                else:\n",
    "                    company[\"search_label\"] = str(0)\n",
    "                    print(name, 'not in crunchbase')\n",
    "            else:\n",
    "                print(\"skip: \", name)\n",
    "            \n",
    "            if (index+1)%20 == 0:\n",
    "                self.save_to_disk()\n",
    "        self.save_to_disk()            \n",
    "                                \n",
    "    def save_to_disk(self):\n",
    "        with open('data/raw_companies.json', 'w') as company_file:\n",
    "            json.dump(self.companies, company_file,indent = 2)\n",
    "            company_file.close()\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENSORO  in crunchbase\n",
      "SENSORO July, 2013 51 - 100 \n",
      "Microsoft Corp not in crunchbase\n",
      "Sumitomo not in crunchbase\n",
      "Manchester City Verve not in crunchbase\n",
      "SalesWings  in crunchbase\n",
      "SalesWings None None\n",
      "SA tech not in crunchbase\n",
      "Avito not in crunchbase\n",
      "timeout of phantomjs\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xizhou\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "CM = CompaniesManager()\n",
    "CM.extract_companies()\n",
    "try:\n",
    "    CM.extend_crunch()\n",
    "except KeyboardInterrupt:\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
