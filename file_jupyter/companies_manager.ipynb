{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-71c1913f26a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdateutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesired_capabilities\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDesiredCapabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import time\n",
    "\n",
    "import sys\n",
    "\n",
    "firefox_capabilities = DesiredCapabilities.FIREFOX\n",
    "firefox_capabilities['marionette'] = True\n",
    "firefox_capabilities['handleAlerts'] = True\n",
    "firefox_capabilities['acceptSslCerts'] = True\n",
    "firefox_capabilities['acceptInsecureCerts'] = True\n",
    "geckoPath = 'driver/geckodriver.exe'\n",
    "#capabilities=firefox_capabilities,\n",
    "firefox = webdriver.Firefox(executable_path=geckoPath)\n",
    "#driver = webdriver.PhantomJS(executable_path='driver/phantomjs.exe')\n",
    "driver = webdriver.Firefox( executable_path=geckoPath)\n",
    "try:\n",
    "    firefox.get('https://www.crunchbase.com/organization/apple')\n",
    "except:\n",
    "    pass\n",
    "driver.get('https://techcrunch.com/')\n",
    "firefox.set_page_load_timeout(2)\n",
    "driver.set_page_load_timeout(30)\n",
    "\n",
    "def existence_in_crunchbase(name):\n",
    "    base_url = 'www.crunchbase.com'\n",
    "    url = 'https://techcrunch.com/search/'+name\n",
    "    url_crunchbase = None\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except KeyboardInterrupt:\n",
    "        sys.exit()\n",
    "    except:\n",
    "        print('timeout of phantomjs')\n",
    "        pass\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    blocks = soup.select(\"h2.post-title a\")\n",
    "    if len(blocks)>0:\n",
    "        url_crunchbase = blocks[0][\"href\"]  \n",
    "        name  = blocks[0].getText()\n",
    " \n",
    "        if base_url not in url_crunchbase:\n",
    "            url_crunchbase = None\n",
    "    \n",
    "    return url_crunchbase\n",
    "            \n",
    "\n",
    "def extract_company_techcrunch(name,url):\n",
    "    try:\n",
    "        firefox.get(url)\n",
    "    except:\n",
    "        pass\n",
    "    founded = None\n",
    "    employees = None\n",
    "    company_name = ''\n",
    "    blocks_dt = []\n",
    "    blocks_dd = []\n",
    "    try:\n",
    "        soup = BeautifulSoup(firefox.page_source, \"html.parser\")\n",
    "        blocks_dt = soup.select(\"div.details dt\")\n",
    "        blocks_dd = soup.select(\"div.details dd\")\n",
    "        company_name_tag = soup.select_one(\"#profile_header_heading\")\n",
    "        if company_name_tag == None:\n",
    "            company_name = ''\n",
    "        else:\n",
    "            company_name = company_name_tag.getText()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    i = 0\n",
    "    while company_name.lower() != name.lower() or len(blocks_dt)==0 :\n",
    "        time.sleep(0.3)\n",
    "        try:\n",
    "            soup = BeautifulSoup(firefox.page_source, \"html.parser\")\n",
    "            company_name_tag = soup.select_one(\"#profile_header_heading\")\n",
    "            if company_name_tag:\n",
    "                company_name = company_name_tag.getText()\n",
    "            else:\n",
    "                company_name = ''\n",
    "            blocks_dt = soup.select(\"div.details dt\")\n",
    "            blocks_dd = soup.select(\"div.details dd\")\n",
    "        except KeyboardInterrupt:\n",
    "            sys.exit()\n",
    "        except:\n",
    "            pass\n",
    "        i=i+1\n",
    "        if i >= 100:\n",
    "            print('fail to crawl ', name , ' in crunchbase')\n",
    "            break\n",
    "\n",
    "    \n",
    "    if company_name.lower() == name.lower():\n",
    "        for index,block in enumerate(blocks_dt):\n",
    "            if 'Founded' in  block.getText() : \n",
    "                founded = blocks_dd[index].getText()\n",
    "            if 'Employees' in block.getText():\n",
    "                employees = blocks_dd[index].getText().split('|')[0]\n",
    "    print( name , founded , employees)\n",
    "    return founded,employees\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "class CompaniesManager:\n",
    "    def __init__(self):\n",
    "        self.companies = []\n",
    "        self.articles = []\n",
    "        self.companies_name = []\n",
    "        self.load_articles()\n",
    "        self.load_companies()\n",
    "        \n",
    "    def load_articles(self):\n",
    "        if os.path.isfile('data/raw_articles.json'):\n",
    "            f = open('data/raw_articles.json')\n",
    "            self.articles = json.load(f)\n",
    "            f.close()\n",
    "            \n",
    "    def load_companies(self):\n",
    "        if os.path.isfile('data/raw_companies.json'):\n",
    "            f = open('data/raw_companies.json')\n",
    "            self.companies = json.load(f)\n",
    "            f.close()      \n",
    "            for company in self.companies:\n",
    "                name = company[\"name\"]\n",
    "                self.companies_name.append(name)\n",
    "        \n",
    "            \n",
    "    def extract_companies(self):\n",
    "        \n",
    "        for index,article in enumerate(self.articles):\n",
    "            for company_name in article[\"companies\"]: \n",
    "                article_extraInfos = article[\"extra_infos\"]\n",
    "                for info in article_extraInfos:\n",
    "                    if info[\"text\"]== company_name:\n",
    "                        relevance = info[\"relevance\"]\n",
    "                        count_in_article = info[\"count\"]\n",
    "                            \n",
    "                if company_name in self.companies_name :\n",
    "                    for company in self.companies:\n",
    "                        if company_name == company[\"name\"] and article[\"id\"] not in company[\"articles\"]: \n",
    "                            company[\"count\"] = company[\"count\"]+1\n",
    "                            company[\"sentiment\"]= company[\"sentiment\"]+article[\"sentiment\"]\n",
    "                            company[\"articles\"].append(article[\"id\"])\n",
    "                            extra_infos = {\n",
    "                                 \"id\":article[\"id\"] ,\n",
    "                                 \"count_in_article\":count_in_article,\n",
    "                                 \"revelance\": relevance       \n",
    "                            }\n",
    "                            company[\"extra_infos\"].append(extra_infos)\n",
    "                            \n",
    "                else:\n",
    "                    company = {\n",
    "                        \"name\": company_name,\n",
    "                        \"dateFound\": int(str(time.time()).split('.')[0]),\n",
    "                        \"count\":1,\n",
    "                        \"sentiment\": article[\"sentiment\"],\n",
    "                        \"articles\": [article[\"id\"]],\n",
    "                        \"extra_infos\":\n",
    "                        [\n",
    "                            {\n",
    "                             \"id\": article[\"id\"],\n",
    "                             \"count_in_article\":count_in_article,\n",
    "                             \"revelance\": relevance\n",
    "                            }  \n",
    "                        ]    \n",
    "                    }\n",
    "                    self.companies.append(company)\n",
    "                    self.companies_name.append(company_name)\n",
    "            \n",
    "        self.save_to_disk()\n",
    "        \n",
    "    def extend_crunch(self):\n",
    "        '''\n",
    "        for test\n",
    "        '''\n",
    "        for index,company in enumerate(self.companies[0:10]):\n",
    "            name = company[\"name\"]\n",
    "            search_label = None\n",
    "            if \"search_label\" in company:\n",
    "                search_label = company[\"search_label\"]\n",
    "                \n",
    "            if search_label==None :\n",
    "                url_crunchbase = existence_in_crunchbase(name)\n",
    "                \n",
    "                if url_crunchbase != None:\n",
    "                    print(name, ' in crunchbase')\n",
    "                    founded,employees = extract_company_techcrunch(name,url_crunchbase)\n",
    "                    print(\"founded: \", founded)\n",
    "                    print(\"employees: \", employees)\n",
    "                    #print(\"site: \", site)\n",
    "                    \n",
    "                else:\n",
    "                    company[\"search_label\"] = str(0)\n",
    "                    print(name, 'not in crunchbase')\n",
    "            else:\n",
    "                print(\"company has been searched : \")\n",
    "                print(name, ' in crunchbase')\n",
    "                founded,employees= extract_company_techcrunch(name,url_crunchbase)\n",
    "                print(\"founded: \", founded)\n",
    "                print(\"employees: \", employees)\n",
    "                #print(\"site: \", site)\n",
    "                print(\"skip: \", name)\n",
    "            \n",
    "        '''\n",
    "        i = 0\n",
    "        for index,company in enumerate(self.companies):\n",
    "            name = company[\"name\"]\n",
    "            search_label = None\n",
    "            if \"search_label\" in company:\n",
    "                search_label = company[\"search_label\"]\n",
    "                \n",
    "            if search_label==None :\n",
    "                url_crunchbase = existence_in_crunchbase(name)\n",
    "                \n",
    "                if url_crunchbase != None:\n",
    "                    print(name, ' in crunchbase')\n",
    "                    i=i+1\n",
    "                    founded,employees = extract_company_techcrunch(name,url_crunchbase)\n",
    "                    company[\"search_label\"] = url_crunchbase\n",
    "                    if founded is not None:\n",
    "                        company[\"foundationDate\"] = founded\n",
    "                    if employees is not None:\n",
    "                        company[\"number_of_employees\"] = employees\n",
    "                    \n",
    "                else:\n",
    "                    company[\"search_label\"] = str(0)\n",
    "                    print(name, 'not in crunchbase')\n",
    "            else:\n",
    "                print(\"skip: \", name)\n",
    "            \n",
    "            if (i+1)%100 == 0:\n",
    "                self.save_to_disk()\n",
    "        self.save_to_disk() \n",
    "        '''\n",
    "                                \n",
    "    def save_to_disk(self):\n",
    "        with open('data/raw_companies.json', 'w') as company_file:\n",
    "            json.dump(self.companies, company_file,indent = 2)\n",
    "            company_file.close()\n",
    "                   \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company has been searched : \n",
      "SENSORO  in crunchbase\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'extract_company_techcrunch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-21125425a96d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCompaniesManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend_crunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-2baf1b26bd7d>\u001b[0m in \u001b[0;36mextend_crunch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"company has been searched : \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' in crunchbase'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mfounded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memployees\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mextract_company_techcrunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0murl_crunchbase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"founded: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfounded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"employees: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memployees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extract_company_techcrunch' is not defined"
     ]
    }
   ],
   "source": [
    "CM = CompaniesManager()\n",
    "CM.extend_crunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
