{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import time\n",
    "\n",
    "firefox_capabilities = DesiredCapabilities.FIREFOX\n",
    "firefox_capabilities['marionette'] = True\n",
    "firefox_capabilities['handleAlerts'] = True\n",
    "firefox_capabilities['acceptSslCerts'] = True\n",
    "firefox_capabilities['acceptInsecureCerts'] = True\n",
    "geckoPath = 'driver/geckodriver.exe'\n",
    "\n",
    "firefox = webdriver.Firefox(capabilities=firefox_capabilities, executable_path=geckoPath)\n",
    "driver = webdriver.PhantomJS(executable_path='driver/phantomjs.exe')\n",
    "\n",
    "\n",
    "#firefox.get('https://www.crunchbase.com/organization/apple')\n",
    "driver.get('https://techcrunch.com/')\n",
    "firefox.set_page_load_timeout(3)\n",
    "driver.set_page_load_timeout(30)\n",
    "def extract_company_techcrunch_2drivers(company):\n",
    "    base_url = 'www.crunchbase.com'\n",
    "    url = 'https://techcrunch.com/search/'+company\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except:\n",
    "        print('timeout of phantomjs')\n",
    "        pass\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    blocks = soup.select(\"h2.post-title a\")\n",
    "    founded = None\n",
    "    employees = None\n",
    "    if len(blocks)>0:\n",
    "        url_crunchbase = blocks[0][\"href\"]  \n",
    "        name  = blocks[0].getText()\n",
    " \n",
    "        if base_url in url_crunchbase:\n",
    "            print(company,' in crunch base')\n",
    "            try:\n",
    "                firefox.get(url_crunchbase)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            blocks_dt = []\n",
    "            blocks_dd = []\n",
    "            try:\n",
    "                soup = BeautifulSoup(firefox.page_source, \"html.parser\")\n",
    "                blocks_dt = soup.select(\"div.details dt\")\n",
    "                blocks_dd = soup.select(\"div.details dd\")\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            i = 0\n",
    "            while len(blocks_dt)==0 or len(blocks_dd)==0:\n",
    "                i=i+1\n",
    "                if i >= 50:\n",
    "                    print('fail to crawl ', company , ' in crunchbase')\n",
    "                    break\n",
    "                time.sleep(0.3)\n",
    "                try:\n",
    "                    soup = BeautifulSoup(firefox.page_source, \"html.parser\")\n",
    "                    blocks_dt = soup.select(\"div.details dt\")\n",
    "                    blocks_dd = soup.select(\"div.details dd\")\n",
    "                except:\n",
    "                    pass\n",
    "                  \n",
    "            for index,block in enumerate(blocks_dt):\n",
    "                if 'Founded' in  block.getText() : \n",
    "                    founded = blocks_dd[index].getText()\n",
    "                if 'Employees' in block.getText():\n",
    "                    employees = blocks_dd[index].getText().split('|')[0]\n",
    "            print(company,founded,employees)\n",
    "    return founded,employees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
